{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# TODO: Mount Google Drive data if necessary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-02T21:58:45.253686Z","iopub.execute_input":"2023-06-02T21:58:45.253941Z","iopub.status.idle":"2023-06-02T21:58:45.259080Z","shell.execute_reply.started":"2023-06-02T21:58:45.253917Z","shell.execute_reply":"2023-06-02T21:58:45.257834Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"* https://github.com/qubvel/segmentation_models.pytorch","metadata":{}},{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nimport numpy as np\nfrom sklearn.metrics import fbeta_score, precision_score, recall_score\nfrom scipy.ndimage.filters import gaussian_filter1d\nimport matplotlib as plt\n\nimport warnings\nfrom sklearn.exceptions import UndefinedMetricWarning\nwarnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T21:58:45.269423Z","iopub.execute_input":"2023-06-02T21:58:45.270065Z","iopub.status.idle":"2023-06-02T21:58:50.578534Z","shell.execute_reply.started":"2023-06-02T21:58:45.270039Z","shell.execute_reply":"2023-06-02T21:58:50.577466Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Download the model. Ran once and created the Kaggle dataset","metadata":{}},{"cell_type":"code","source":"def download_and_save_resnet50(output_path):\n    model = fcn_resnet50(FCN_ResNet50_Weights.DEFAULT)\n    torch.save(model, output_path)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T21:58:50.583868Z","iopub.execute_input":"2023-06-02T21:58:50.586085Z","iopub.status.idle":"2023-06-02T21:58:50.592781Z","shell.execute_reply.started":"2023-06-02T21:58:50.586048Z","shell.execute_reply":"2023-06-02T21:58:50.591476Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Constants & config","metadata":{}},{"cell_type":"code","source":"MODEL_PATH = '/kaggle/input/resnet50-pretrained/model'\n\nYX_DIM = 32  # Specify only one dimension and use square patches.\nZ_START = 26\nZ_END = 36\nZ_STEP = 2\nZ_DIM = (Z_END - Z_START) // Z_STEP\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nBSIZE = 32\n\nTQDM_OFF = False","metadata":{"execution":{"iopub.status.busy":"2023-06-02T21:58:50.594254Z","iopub.execute_input":"2023-06-02T21:58:50.594879Z","iopub.status.idle":"2023-06-02T21:58:50.640120Z","shell.execute_reply.started":"2023-06-02T21:58:50.594847Z","shell.execute_reply":"2023-06-02T21:58:50.639022Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Dataset definition","metadata":{}},{"cell_type":"code","source":"def load_mask(fragment_name, split_name):\n    print(f\"Loading mask {split_name}/{fragment_name}\")\n    return np.array(Image.open(f\"/kaggle/input/vesuvius-challenge-ink-detection/{split_name}/{fragment_name}/mask.png\"))\n\ndef load_inklabels(fragment_name, split_name):\n    print(f\"Loading inklabels {split_name}/{fragment_name}\")\n    return np.array(Image.open(f\"/kaggle/input/vesuvius-challenge-ink-detection/{split_name}/{fragment_name}/inklabels.png\")).astype('float32')\n\ndef load_surface(fragment_name, split_name):\n    print(f\"Loading surface\")\n    surface = None\n    for i in tqdm(range(Z_DIM), disable=TQDM_OFF):\n        l = Z_START + i * Z_STEP\n        sslice = np.array(Image.open(f\"/kaggle/input/vesuvius-challenge-ink-detection/{split_name}/{fragment_name}/surface_volume/{l:02}.tif\"))\n        sslice = (sslice / 2**16).astype('float32')\n        surface = surface if surface is not None else np.zeros([Z_DIM, *sslice.shape], dtype='float32')\n        surface[i] = sslice\n    return surface\n\nclass SlicedDataset(torch.utils.data.Dataset):\n    def __init__(self, fragment_name, split_name):\n        self.fragment_name = fragment_name\n        self.split_name = split_name\n        self.surface = load_surface(fragment_name, split_name)\n        self.mask = load_mask(fragment_name, split_name)\n        self.inklabels = load_inklabels(fragment_name, split_name)\n\n    def __len__(self):\n        return (self.surface.shape[1] - YX_DIM) * (self.surface.shape[2] - YX_DIM)\n\n    def __getitem__(self, idx):\n        y = idx // (self.surface.shape[2] - YX_DIM)\n        x = idx % (self.surface.shape[2] - YX_DIM)\n        surface = self.surface[:, y:y + YX_DIM, x:x + YX_DIM]\n        labels = self.inklabels[y:y + YX_DIM, x:x + YX_DIM].reshape((1, YX_DIM, YX_DIM))\n        return surface, labels","metadata":{"execution":{"iopub.status.busy":"2023-06-02T21:58:50.646687Z","iopub.execute_input":"2023-06-02T21:58:50.647343Z","iopub.status.idle":"2023-06-02T21:58:50.668999Z","shell.execute_reply.started":"2023-06-02T21:58:50.647297Z","shell.execute_reply":"2023-06-02T21:58:50.667832Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"x = SlicedDataset('1', 'train')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T21:58:50.673363Z","iopub.execute_input":"2023-06-02T21:58:50.673813Z","iopub.status.idle":"2023-06-02T21:59:02.010755Z","shell.execute_reply.started":"2023-06-02T21:58:50.673780Z","shell.execute_reply":"2023-06-02T21:59:02.009726Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Loading surface\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ec4630289124498acb631a608b3cba5"}},"metadata":{}},{"name":"stdout","text":"Loading mask train/1\nLoading inklabels train/1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Model definition","metadata":{}},{"cell_type":"code","source":"fcn_model = torch.load(MODEL_PATH)\nfcn_model = fcn_model\nfcn_model.backbone.conv1 = torch.nn.Conv2d(\n    Z_DIM, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nfcn_model.classifier[4] = torch.nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n\nfcn_model = fcn_model.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T21:59:02.013060Z","iopub.execute_input":"2023-06-02T21:59:02.013824Z","iopub.status.idle":"2023-06-02T21:59:06.817575Z","shell.execute_reply.started":"2023-06-02T21:59:02.013787Z","shell.execute_reply":"2023-06-02T21:59:06.816592Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train_on_fragment(fragment_name):\n    ds = SlicedDataset(fragment_name, 'train')\n    dl = torch.utils.data.DataLoader(ds, batch_size=BSIZE, shuffle=True)\n    criterion = torch.nn.BCELoss()\n    optimizer = torch.optim.Adam(fcn_model.parameters())\n    \n    losses = []\n    fbetas = []\n    precisions = []\n    recalls = []\n    \n    for surface, inklabels in (pbar := tqdm(dl, disable=TQDM_OFF)):\n        preds = torch.sigmoid(fcn_model(surface.to(DEVICE))['out'])\n        pred_ink = preds.detach().gt(0.5).cpu().int()\n        loss = criterion(preds, inklabels.to(DEVICE))\n        loss.backward()\n        optimizer.step()\n        \n        fbeta = fbeta_score(inklabels.view(-1).numpy(), pred_ink.view(-1).numpy(), beta=0.5)\n        precision = precision_score(inklabels.view(-1).numpy(), pred_ink.view(-1).numpy())\n        recall = recall_score(inklabels.view(-1).numpy(), pred_ink.view(-1).numpy())\n        \n        pbar.set_postfix({\"loss\": loss, \"prec\": precision, \"rec\": recall, \"fbeta\": fbeta})\n        \n        fbetas.append(fbeta)\n        losses.append(loss.detach().cpu().float())\n        precisions.append(precision)\n        recalls.append(recall)\n\n    plt.plot(gaussian_filter1d(losses, sigma=25), label='loss')\n    plt.plot(gaussian_filter1d(precisions, sigma=25), label='precisions')\n    plt.plot(gaussian_filter1d(recalls, sigma=25), label='recalls')\n    plt.plot(gaussian_filter1d(fbetas, sigma=25), label='fbetas')\n\ntrain_on_fragment('1')\ntrain_on_fragment('2')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T21:59:06.819158Z","iopub.execute_input":"2023-06-02T21:59:06.819589Z","iopub.status.idle":"2023-06-02T22:33:51.811865Z","shell.execute_reply.started":"2023-06-02T21:59:06.819552Z","shell.execute_reply":"2023-06-02T22:33:51.810119Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Loading surface\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"969f918c86ef4962941023b856cfb24d"}},"metadata":{}},{"name":"stdout","text":"Loading mask train/1\nLoading inklabels train/1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1603826 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"843080c625c04489afba1840af10985f"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         recall \u001b[38;5;241m=\u001b[39m recall_score(inklabels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy(), pred_ink\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     16\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprec\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrec\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m: fbeta})\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtrain_on_fragment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m train_on_fragment(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mtrain_on_fragment\u001b[0;34m(fragment_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(fcn_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m surface, inklabels \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m tqdm(dl, disable\u001b[38;5;241m=\u001b[39mTQDM_OFF)):\n\u001b[0;32m----> 7\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mfcn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m     pred_ink \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mgt(\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mint()\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(preds, inklabels\u001b[38;5;241m.\u001b[39mto(DEVICE))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/segmentation/_utils.py:27\u001b[0m, in \u001b[0;36m_SimpleSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m result \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, size\u001b[38;5;241m=\u001b[39minput_shape, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"%%time\nprint(fcn_model(torch.zeros(BSIZE, Z_DIM, 64, 64).to(DEVICE))['out'].shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T22:33:51.812720Z","iopub.status.idle":"2023-06-02T22:33:51.813558Z","shell.execute_reply.started":"2023-06-02T22:33:51.813309Z","shell.execute_reply":"2023-06-02T22:33:51.813332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = SlicedDataset('1', 'train')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T22:33:51.815285Z","iopub.status.idle":"2023-06-02T22:33:51.815813Z","shell.execute_reply.started":"2023-06-02T22:33:51.815575Z","shell.execute_reply":"2023-06-02T22:33:51.815597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ds.inklabels.sum() / (ds.inklabels.shape[0] * ds.inklabels.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T22:33:51.817563Z","iopub.status.idle":"2023-06-02T22:33:51.818091Z","shell.execute_reply.started":"2023-06-02T22:33:51.817824Z","shell.execute_reply":"2023-06-02T22:33:51.817848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train on fragments 1 and 2","metadata":{}},{"cell_type":"markdown","source":"Validate on fragment 3. Dipslay predicted image for different thresholds.","metadata":{}},{"cell_type":"markdown","source":"Pick the best threshold","metadata":{}},{"cell_type":"markdown","source":"Test output serialization on train data","metadata":{}},{"cell_type":"markdown","source":"Generate test predictions","metadata":{}}]}