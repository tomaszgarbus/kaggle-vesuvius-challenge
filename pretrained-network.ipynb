{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"try:\n  from google.colab import drive\n  drive.mount('/content/drive')\nexcept:\n  pass","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"yOyDT3yK3mFx","outputId":"bd0ebd51-e389-4506-9fb1-970456c7b7f0","execution":{"iopub.status.busy":"2023-06-07T18:52:31.241138Z","iopub.execute_input":"2023-06-07T18:52:31.241473Z","iopub.status.idle":"2023-06-07T18:52:31.253973Z","shell.execute_reply.started":"2023-06-07T18:52:31.241432Z","shell.execute_reply":"2023-06-07T18:52:31.252870Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle\n!mkdir /kaggle/input\n!ln -s /content/drive/Shareddrives/\"Kaggle data\"/vesuvius-challenge-ink-detection /kaggle/input/\n!ln -s /content/drive/Shareddrives/\"Kaggle data\"/resnet50-pretrained /kaggle/input/\n!ln -s /content/drive/Shareddrives/\"Kaggle data\"/working /kaggle/","metadata":{"id":"4yMS8MI442D3","execution":{"iopub.status.busy":"2023-06-07T18:52:31.256097Z","iopub.execute_input":"2023-06-07T18:52:31.256533Z","iopub.status.idle":"2023-06-07T18:52:37.207508Z","shell.execute_reply.started":"2023-06-07T18:52:31.256477Z","shell.execute_reply":"2023-06-07T18:52:37.205981Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘/kaggle’: File exists\nmkdir: cannot create directory ‘/kaggle/input’: File exists\nln: failed to create symbolic link '/kaggle/input/vesuvius-challenge-ink-detection': File exists\nln: failed to create symbolic link '/kaggle/input/resnet50-pretrained': File exists\nln: failed to create symbolic link '/kaggle/working': File exists\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* https://github.com/qubvel/segmentation_models.pytorch","metadata":{"id":"7ifZeAK93mFy"}},{"cell_type":"markdown","source":"Imports","metadata":{"id":"KhNhdFub3mF0"}},{"cell_type":"code","source":"import torch\nfrom torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nimport numpy as np\nfrom sklearn.metrics import fbeta_score, precision_score, recall_score\nfrom scipy.ndimage.filters import gaussian_filter1d\nimport matplotlib.pyplot as plt\nimport datetime\n\nfrom collections import defaultdict\n\nimport pandas as pd\n\nimport gc\n\nimport warnings\nfrom sklearn.exceptions import UndefinedMetricWarning\nwarnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)","metadata":{"id":"wd3VIF6a3mF0","outputId":"a5a076ff-fb60-4319-d72d-2f9685b4f789","execution":{"iopub.status.busy":"2023-06-07T18:52:37.213883Z","iopub.execute_input":"2023-06-07T18:52:37.216493Z","iopub.status.idle":"2023-06-07T18:52:41.508862Z","shell.execute_reply.started":"2023-06-07T18:52:37.216448Z","shell.execute_reply":"2023-06-07T18:52:41.507786Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/486318880.py:9: DeprecationWarning: Please use `gaussian_filter1d` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n  from scipy.ndimage.filters import gaussian_filter1d\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Download the model. Ran once and created the Kaggle dataset","metadata":{"id":"_hrEMTG43mF0"}},{"cell_type":"code","source":"def download_and_save_resnet50(output_path):\n    model = fcn_resnet50(FCN_ResNet50_Weights.DEFAULT)\n    torch.save(model, output_path)","metadata":{"id":"4rTzN70O3mF1","execution":{"iopub.status.busy":"2023-06-07T18:52:41.510169Z","iopub.execute_input":"2023-06-07T18:52:41.511191Z","iopub.status.idle":"2023-06-07T18:52:41.516421Z","shell.execute_reply.started":"2023-06-07T18:52:41.511156Z","shell.execute_reply":"2023-06-07T18:52:41.515508Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Constants & config","metadata":{"id":"G_Py6FP33mF1"}},{"cell_type":"code","source":"MODEL_PATH = '/kaggle/input/resnet50-pretrained/model'\n\nYX_DIM = 32  # Specify only one dimension and use square patches.\nZ_START = 26\nZ_END = 32\nZ_STEP = 2\nZ_DIM = (Z_END - Z_START) // Z_STEP\nassert Z_DIM == 3\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nBSIZE = 256  # 256 is best\nLR = 0.003\n\nTQDM_OFF = True\n\nPLOT_EVERY = 1000  # Steps\nMAX_STEPS = 10000\n\nTH = 0.5","metadata":{"id":"ca5aCn7r3mF1","execution":{"iopub.status.busy":"2023-06-07T18:52:41.518547Z","iopub.execute_input":"2023-06-07T18:52:41.519239Z","iopub.status.idle":"2023-06-07T18:52:41.559303Z","shell.execute_reply.started":"2023-06-07T18:52:41.519207Z","shell.execute_reply":"2023-06-07T18:52:41.558193Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Dataset definition","metadata":{"id":"LPYZDWng3mF2"}},{"cell_type":"code","source":"def load_mask(fragment_name, split_name):\n    print(f\"Loading mask {split_name}/{fragment_name}\")\n    return np.array(Image.open(f\"/kaggle/input/vesuvius-challenge-ink-detection/{split_name}/{fragment_name}/mask.png\"))\n\ndef load_inklabels(fragment_name, split_name):\n    if split_name == 'test':\n        return None\n    print(f\"Loading inklabels {split_name}/{fragment_name}\")\n    return np.array(Image.open(f\"/kaggle/input/vesuvius-challenge-ink-detection/{split_name}/{fragment_name}/inklabels.png\")).astype('float32')\n\ndef load_surface(fragment_name, split_name):\n    print(f\"Loading surface\")\n    surface = None\n    for i in tqdm(range(Z_DIM), disable=TQDM_OFF):\n        l = Z_START + i * Z_STEP\n        sslice = np.array(Image.open(f\"/kaggle/input/vesuvius-challenge-ink-detection/{split_name}/{fragment_name}/surface_volume/{l:02}.tif\"))\n        sslice = (sslice / 2**16).astype('float32')\n        surface = surface if surface is not None else np.zeros([Z_DIM, *sslice.shape], dtype='float32')\n        surface[i] = sslice\n    return surface\n\nclass SlicedDataset(torch.utils.data.Dataset):\n    def __init__(self, fragment_name, split_name):\n        self.fragment_name = fragment_name\n        self.split_name = split_name\n        self.surface = load_surface(fragment_name, split_name)\n        self.mask = load_mask(fragment_name, split_name)\n        self.inklabels = load_inklabels(fragment_name, split_name)\n        if self.inklabels is None:\n            self.inklabels = np.zeros(self.mask.shape)\n\n    def __len__(self):\n        return (self.surface.shape[1] - YX_DIM) * (self.surface.shape[2] - YX_DIM)\n\n    def getitem(self, y, x):\n        surface = self.surface[:, y:y + YX_DIM, x:x + YX_DIM]\n        labels = self.inklabels[y:y + YX_DIM, x:x + YX_DIM].reshape((1, YX_DIM, YX_DIM))\n        return surface, labels, (y, x)\n\n    def __getitem__(self, idx):\n        y = idx // (self.surface.shape[2] - YX_DIM)\n        x = idx % (self.surface.shape[2] - YX_DIM)\n        return self.getitem(y, x)","metadata":{"id":"Xqs_bEtO3mF2","execution":{"iopub.status.busy":"2023-06-07T18:52:41.561218Z","iopub.execute_input":"2023-06-07T18:52:41.561738Z","iopub.status.idle":"2023-06-07T18:52:41.579830Z","shell.execute_reply.started":"2023-06-07T18:52:41.561691Z","shell.execute_reply":"2023-06-07T18:52:41.578851Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"x = SlicedDataset('1', 'train')\ndel x\ngc.collect()","metadata":{"id":"lLV2H2SI3mF2","outputId":"d5018365-4c76-45db-b22f-dbebcd6d20af","execution":{"iopub.status.busy":"2023-06-07T18:52:41.581610Z","iopub.execute_input":"2023-06-07T18:52:41.582582Z","iopub.status.idle":"2023-06-07T18:52:47.798955Z","shell.execute_reply.started":"2023-06-07T18:52:41.582547Z","shell.execute_reply":"2023-06-07T18:52:47.797901Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Loading surface\nLoading mask train/1\nLoading inklabels train/1\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"Model definition","metadata":{"id":"FSRT5wDJ3mF3"}},{"cell_type":"code","source":"fcn_model = torch.load(MODEL_PATH)\nfcn_model = fcn_model\n# fcn_model.backbone.conv1 = torch.nn.Conv2d(\n#     Z_DIM, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nfcn_model.classifier[4] = torch.nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n\nfcn_model = fcn_model.to(DEVICE)","metadata":{"id":"KTv0uktr3mF4","execution":{"iopub.status.busy":"2023-06-07T18:53:02.429940Z","iopub.execute_input":"2023-06-07T18:53:02.430311Z","iopub.status.idle":"2023-06-07T18:53:07.076172Z","shell.execute_reply.started":"2023-06-07T18:53:02.430263Z","shell.execute_reply":"2023-06-07T18:53:07.075211Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Freeze backbone, then unfreeze backbone.conv1","metadata":{"id":"Boy65qfbIX3x"}},{"cell_type":"code","source":"# for param in fcn_model.backbone.parameters():\n#   param.requires_grad = False\n\n# for param in fcn_model.backbone.conv1.parameters():\n#   param.requires_grad = True","metadata":{"id":"HbQtHuM0IJyv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train on fragments 1 and 2","metadata":{"id":"p6E6neRKFyt6"}},{"cell_type":"code","source":"def train_on_fragment(fragment_name):\n    ds = SlicedDataset(fragment_name, 'train')\n    dl = torch.utils.data.DataLoader(ds, batch_size=BSIZE, shuffle=True)\n    class WeightedBCELoss(torch.nn.Module):\n      def __init__(self):\n          super().__init__()\n\n      def forward(self, pred, actual):\n          weights = torch.ones(actual.shape).to(DEVICE)\n          weights[torch.where(actual == 1.)] = 3.\n          return torch.nn.BCELoss(weights)(pred, actual)\n\n    criterion = WeightedBCELoss()\n    optimizer = torch.optim.Adam(fcn_model.parameters(), lr=LR)\n\n    losses = []\n    fbetas = []\n    precisions = []\n    recalls = []\n    gradnorms = []\n    predsnorms = []\n    livegen = np.zeros(ds.surface.shape[1:])\n\n    def gradnorm():\n        grads = [\n            param.grad.detach().flatten()\n            for param in fcn_model.parameters()\n            if param.grad is not None\n        ]\n        norm = torch.cat(grads).norm().cpu()\n        return norm\n\n    def plot():\n        fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(15, 3))\n        fig.suptitle(f'Training on {fragment_name}')\n        axs[0].plot(gaussian_filter1d(losses, sigma=25), label='loss')\n        axs[0].plot(gaussian_filter1d(precisions, sigma=25), label='precisions')\n        axs[0].plot(gaussian_filter1d(recalls, sigma=25), label='recalls')\n        axs[0].plot(gaussian_filter1d(fbetas, sigma=25), label='fbetas')\n        axs[1].plot(gaussian_filter1d(gradnorms, sigma=25), label='gradnorms')\n        axs[2].plot(gaussian_filter1d(predsnorms, sigma=25), label='predsnorms')\n        axs[3].imshow(livegen)\n        axs[0].legend()\n        axs[1].legend()\n        axs[2].legend()\n        plt.savefig(f'/kaggle/working/training_{fragment_name}_{datetime.datetime.now().strftime(\"%d-%m-%H:%M:%S\")}.png')\n        plt.show()\n\n    for i, (surface, inklabels, (ys, xs)) in enumerate(pbar := tqdm(dl, disable=TQDM_OFF)):\n        if i > MAX_STEPS:\n            break\n        optimizer.zero_grad()\n\n        preds = torch.sigmoid(fcn_model(surface.to(DEVICE))['out'])\n        pred_ink = preds.detach().gt(0.5).cpu().int()\n        loss = criterion(preds, inklabels.to(DEVICE))\n        loss.backward()\n        optimizer.step()\n\n        # TODO: vectorize\n        for j in range(BSIZE):\n          livegen[ys[j]:ys[j] + YX_DIM, xs[j]:xs[j] + YX_DIM] = preds[j, 0].detach().cpu().numpy()\n\n        fbeta = fbeta_score(inklabels.view(-1).numpy(), pred_ink.view(-1).numpy(), beta=0.5)\n        precision = precision_score(inklabels.view(-1).numpy(), pred_ink.view(-1).numpy())\n        recall = recall_score(inklabels.view(-1).numpy(), pred_ink.view(-1).numpy())\n\n        fbetas.append(fbeta)\n        losses.append(loss.detach().cpu().float())\n        precisions.append(precision)\n        recalls.append(recall)\n        gradnorms.append(gradnorm())\n        predsnorms.append(preds.detach().norm().cpu())\n\n        pbar.set_postfix({\n            \"loss\": loss,\n            \"prec\": precision,\n            \"rec\": recall,\n            \"fbeta\": fbeta,\n            \"gradnorm\": gradnorms[-1],\n            \"predsnorm\": predsnorms[-1]})\n\n        if i % PLOT_EVERY == PLOT_EVERY - 1:\n            plot()\n\n    plot()\n\n    # Cleanup\n    del ds\n    del dl\n    del livegen\n    torch.save(fcn_model, f'/kaggle/working/model_{datetime.datetime.now().strftime(\"%d-%m-%H:%M:%S\")}')\n\n# train_on_fragment('1')\n# gc.collect()\ntrain_on_fragment('2')\ngc.collect()","metadata":{"id":"VwU3VPHa3mF4","outputId":"14bf3ffe-f649-4988-a5f5-55502ea6f8ef","execution":{"iopub.status.busy":"2023-06-07T18:53:30.449516Z","iopub.execute_input":"2023-06-07T18:53:30.449893Z","iopub.status.idle":"2023-06-07T18:55:41.434599Z","shell.execute_reply.started":"2023-06-07T18:53:30.449860Z","shell.execute_reply":"2023-06-07T18:55:41.432834Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Loading surface\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (140973980 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Loading mask train/2\nLoading inklabels train/2\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 96\u001b[0m\n\u001b[1;32m     92\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(fcn_model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# train_on_fragment('1')\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[43mtrain_on_fragment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n","Cell \u001b[0;32mIn[9], line 66\u001b[0m, in \u001b[0;36mtrain_on_fragment\u001b[0;34m(fragment_name)\u001b[0m\n\u001b[1;32m     64\u001b[0m fbeta \u001b[38;5;241m=\u001b[39m fbeta_score(inklabels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy(), pred_ink\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy(), beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     65\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(inklabels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy(), pred_ink\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m---> 66\u001b[0m recall \u001b[38;5;241m=\u001b[39m \u001b[43mrecall_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43minklabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_ink\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m fbetas\u001b[38;5;241m.\u001b[39mappend(fbeta)\n\u001b[1;32m     69\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mfloat())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2098\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecall_score\u001b[39m(\n\u001b[1;32m   1968\u001b[0m     y_true,\n\u001b[1;32m   1969\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1975\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1976\u001b[0m ):\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m \n\u001b[1;32m   1979\u001b[0m \u001b[38;5;124;03m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;124;03m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2098\u001b[0m     _, r, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2099\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2100\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1577\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1577\u001b[0m MCM \u001b[38;5;241m=\u001b[39m \u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplewise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamplewise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1584\u001b[0m tp_sum \u001b[38;5;241m=\u001b[39m MCM[:, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1585\u001b[0m pred_sum \u001b[38;5;241m=\u001b[39m tp_sum \u001b[38;5;241m+\u001b[39m MCM[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:489\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmultilabel_confusion_matrix\u001b[39m(\n\u001b[1;32m    390\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplewise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    391\u001b[0m ):\n\u001b[1;32m    392\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m            [1, 2]]])\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m column_or_1d(sample_weight)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:113\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m         unique_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    120\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot y_true=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y_true)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe true labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/arraysetops.py:781\u001b[0m, in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_union1d_dispatcher)\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munion1d\u001b[39m(ar1, ar2):\n\u001b[1;32m    749\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m    Find the union of two arrays.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03m    array([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"Define a function to generate the image","metadata":{"id":"YiBWmGnG0cMS"}},{"cell_type":"code","source":"def generate_raw_prediction(dataset):\n    out = np.zeros(dataset.surface.shape[1:])\n    # TODO: handle borders better\n    for y in tqdm(range(0, dataset.surface.shape[1] - YX_DIM, YX_DIM), disable=TQDM_OFF):\n        for x in range(0, dataset.surface.shape[2] - YX_DIM, YX_DIM):\n            surface, _, _ = dataset.getitem(y, x)\n            surface = torch.Tensor(np.expand_dims(surface, axis=0)).to(DEVICE)\n            preds = torch.sigmoid(fcn_model(torch.Tensor(surface).to(DEVICE))['out'])\n            out[y:y + YX_DIM, x:x + YX_DIM] = preds[0].detach().cpu().numpy()\n    out *= dataset.mask\n    return out\n\n\ndef apply_thr(raw, thr):\n    out = np.copy(raw)\n    out[np.where(out < thr)] = 0.\n    out[np.where(out >= thr)] = 1.\n    return out","metadata":{"id":"-lVosqCW0bcH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validate on fragment 3. Dipslay predicted image.","metadata":{"id":"vJtXiiFf3mF5"}},{"cell_type":"code","source":"%%time\n\ndef update_threshold():\n    global TH\n    thresholds = np.arange(0.1, 0.5, 0.07)\n    ds = SlicedDataset('3', 'train')\n    raw = generate_raw_prediction(ds)\n    plt.imshow(raw)\n    plt.show()\n\n    best_fbeta = 0.0\n    for thr in thresholds:\n        out = apply_thr(raw, thr)\n        fbeta = fbeta_score(ds.inklabels.flatten().astype(int), out.flatten().astype(int), beta=0.5)\n        precision = precision_score(ds.inklabels.flatten().astype(int), out.flatten().astype(int))\n        recall = recall_score(ds.inklabels.flatten().astype(int), out.flatten().astype(int))\n\n        print(f\"thr: {thr} fbeta: {fbeta} precision: {precision} recall: {recall}\")\n\n        if fbeta > best_fbeta:\n            best_fbeta = fbeta\n            TH = thr\n\nupdate_threshold()\n\n\ngc.collect()","metadata":{"id":"mLt_XSTD14le","outputId":"66ff93de-6efc-492d-a198-87fcbb53b037"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test output serialization on train data","metadata":{"id":"PxpJIbDF3mF5"}},{"cell_type":"code","source":"def rle(preds):\n    preds = preds.flatten()\n    starts = 2 + np.array(np.where(preds[1:] - preds[:-1] == 1.)).flatten()\n    ends = 2 + np.array(np.where(preds[1:] - preds[:-1] == -1.)).flatten()\n    return np.stack([starts, ends - starts], axis=1)\n\ndef serialize_rle(rle):\n    return ' '.join(f\"{x[0]} {x[1]}\" for x in rle)","metadata":{"id":"dr8bTRYCDv-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = SlicedDataset('3', 'train')\nprint(serialize_rle(rle(ds.inklabels)))\n!cat /kaggle/input/vesuvius-challenge-ink-detection/train/3/inklabels_rle.csv","metadata":{"id":"ERwfhh5UGeRi","outputId":"d53cdeb3-4754-422d-8027-c5b2cf7a1617"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate test predictions","metadata":{"id":"FCptxBUK3mF6"}},{"cell_type":"code","source":"submission = defaultdict(list)\n\nfor fragment_name in os.listdir('/kaggle/input/vesuvius-challenge-ink-detection/test/'):\n    ds = SlicedDataset(fragment_name, 'test')\n    out = apply_thr(generate_raw_prediction(ds), TH)\n\n    submission[\"Id\"].append(fragment_name)\n    submission[\"Predicted\"].append(serialize_rle(rle(out)))\n\npd.DataFrame.from_dict(submission).to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"id":"RpeiiD4qHKQ8","outputId":"ae6d6af5-9d2e-4a30-9303-c4168d4b8a4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(submission)","metadata":{"id":"lbs259PrIO4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cut -c-100 /kaggle/working/submission.csv","metadata":{"id":"P9n1xG3DKER8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"a91WpYXjKedg"},"execution_count":null,"outputs":[]}]}