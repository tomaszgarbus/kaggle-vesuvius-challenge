{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Imports and constants","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport torch\nimport torch.utils.data as thd\nimport torch.nn as nn\n\nfrom sklearn.metrics import fbeta_score, precision_score, recall_score\n\nfrom scipy.ndimage.filters import gaussian_filter1d\n\nimport matplotlib.pyplot as plt\n\nfrom collections import defaultdict\nimport os\n\nimport gc\n\nfrom operator import itemgetter\n\nfrom pympler import tracker\n\nBATCH_SIZE = 256\nBUFFER = 10  # Buffer size in both dimensions: x and y. Effective patch size is [BUFFER * 2 + 1, BUFFER * 2 + 1, Z_DIM].\nSLICES = 65\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nLEARNING_RATE = 0.005\nZ_START = 25\nZ_END = 45\nZ_STEP = 2\nZ_DIM = (Z_END - Z_START) // Z_STEP\nTRAIN_ON_FRAGMENTS = [1, 2]\nVAL_FRAGMENT = 3\n\nMAX_TRAIN_STEPS = 500000000\nMAX_VAL_STEPS = 1000\nPRINT_EVERY = 20000000","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-25T14:22:37.554386Z","iopub.execute_input":"2023-05-25T14:22:37.554781Z","iopub.status.idle":"2023-05-25T14:22:42.564700Z","shell.execute_reply.started":"2023-05-25T14:22:37.554750Z","shell.execute_reply":"2023-05-25T14:22:42.563519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, let's see if we can fit all one full fragment into memory at once.","metadata":{}},{"cell_type":"code","source":"def pad_array(array):\n    padding = (\n        (BUFFER, BUFFER),\n        (BUFFER, BUFFER),\n    )\n    return np.pad(array, padding)\n\ndef load_fragment_surface(fragment, split='train'):\n    print(\"Loading fragment %s surface\" % fragment)\n    surface_path = Path(\"/kaggle/input/vesuvius-challenge-ink-detection/%s/%s/surface_volume\" % (split, fragment))\n    return np.array([\n        (pad_array(np.array(Image.open(f))) / (2 ** 16)).astype('float16')\n        for f in tqdm(sorted(surface_path.rglob(\"*.tif\"))[Z_START:Z_END:Z_STEP])\n    ])\n\ndef load_mask(fragment, split='train'):\n    print(\"Loading fragment %s mask\" % fragment)\n    mask_path = Path(\"/kaggle/input/vesuvius-challenge-ink-detection/%s/%s/mask.png\" % (split, fragment))\n    return pad_array(np.array(Image.open(mask_path)))\n\ndef load_inklabels(fragment, split='train'):\n    print(\"Loading fragment %s labels\" % fragment)\n    inklabels_path = Path(\"/kaggle/input/vesuvius-challenge-ink-detection/%s/%s/inklabels.png\" % (split, fragment))\n    return pad_array(np.array(Image.open(inklabels_path)))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T14:22:42.567005Z","iopub.execute_input":"2023-05-25T14:22:42.567729Z","iopub.status.idle":"2023-05-25T14:22:42.578414Z","shell.execute_reply.started":"2023-05-25T14:22:42.567685Z","shell.execute_reply":"2023-05-25T14:22:42.577162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SingleFragmentDataset(thd.Dataset):\n    def __init__(self, fragment, is_test=False):\n        self.is_test = is_test\n        split = 'test' if is_test else 'train'\n        self.surface = load_fragment_surface(fragment, split)\n        print(self.surface.dtype)\n        self.mask = load_mask(fragment, split)\n        self.inklabels = load_inklabels(fragment, split) if not is_test else None\n        self.pixels = np.stack(np.where(self.mask == 1), axis=1)\n    \n    def __len__(self):\n        return self.pixels.shape[0]\n    \n    def get_pixel_number(self, y, x):\n        return 1 + y * self.surface.shape[2] + x\n    \n    def __getitem__(self, index):\n        y, x = self.pixels[index]\n        y_start = y - BUFFER\n        y_end = y + BUFFER + 1\n        x_start = x - BUFFER\n        x_end = x + BUFFER + 1\n        patch_surface = np.s_[:, y_start:y_end, x_start:x_end]\n        patch_labels = np.s_[y_start:y_end, x_start:x_end]\n        surface = self.surface[patch_surface].astype(np.float32)\n        labels = self.inklabels[y, x].reshape((1, )).astype(np.float32) if not self.is_test else None\n        return (surface, labels) if not self.is_test else (surface, self.get_pixel_number(y, x))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T14:23:07.444146Z","iopub.execute_input":"2023-05-25T14:23:07.444659Z","iopub.status.idle":"2023-05-25T14:23:07.458644Z","shell.execute_reply.started":"2023-05-25T14:23:07.444618Z","shell.execute_reply":"2023-05-25T14:23:07.457009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the model","metadata":{}},{"cell_type":"code","source":"convnet = nn.Sequential(\n    nn.Conv2d(Z_DIM, 32, kernel_size=3, stride=1, dilation=1, padding='same'),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Conv2d(32, 16, kernel_size=3, stride=1, dilation=1, padding='same'),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.BatchNorm2d(16),\n    nn.Conv2d(16, 8, kernel_size=3, stride=1, dilation=1, padding='same'),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.BatchNorm2d(8),\n    nn.Conv2d(8, 1, kernel_size=3, stride=1, dilation=1, padding='same'),\n    nn.ReLU(),\n    nn.Flatten(),\n    nn.Linear((2 * BUFFER + 1) ** 2, 128),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.Linear(128, 64),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.Linear(64, 1),\n    nn.Sigmoid()\n).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:51:00.259467Z","iopub.execute_input":"2023-05-25T11:51:00.260076Z","iopub.status.idle":"2023-05-25T11:51:04.943393Z","shell.execute_reply.started":"2023-05-25T11:51:00.260042Z","shell.execute_reply":"2023-05-25T11:51:04.942434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train the model","metadata":{}},{"cell_type":"code","source":"%%time\n\ncriterion = nn.BCELoss()\n\n\ndef train(fragment_number):\n    train_dataset = SingleFragmentDataset(fragment_number)\n    print(train_dataset.surface.shape)\n    train_loader = thd.DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n    \n    print(gc.collect())\n    mem = tracker.SummaryTracker()\n    print(sorted(mem.create_summary(), reverse=True, key=itemgetter(2))[:10])\n    \n    losses = []\n    accs = []\n    fbetas = []\n\n    convnet.train()\n    optimizer = torch.optim.SGD(convnet.parameters(), lr=LEARNING_RATE)\n    for i, (xs, ys) in enumerate(pbar := tqdm(train_loader)):\n        if i > MAX_TRAIN_STEPS:\n            break\n        optimizer.zero_grad()\n        outputs = convnet(xs.to(DEVICE))\n        if i % PRINT_EVERY == PRINT_EVERY - 1:\n            print(outputs)\n            plt.plot(gaussian_filter1d(losses, sigma=10), label='loss')\n            plt.plot(gaussian_filter1d(accs, sigma=10), label='accs')\n            plt.plot(gaussian_filter1d(fbetas, sigma=10), label='fbetas')\n            plt.legend()\n        loss = criterion(outputs, ys.to(DEVICE))\n        pred_ink = outputs.detach().gt(0.4).cpu().int()\n        accuracy = (pred_ink == ys).sum().float().div(ys.size(0))\n        fbeta = fbeta_score(ys.view(-1).numpy(), pred_ink.view(-1).numpy(), beta=0.5)\n        pbar.set_postfix({\"loss\": loss, \"acc\": accuracy, \"fbeta\": fbeta})\n        loss.backward()\n        optimizer.step()\n\n        fbetas.append(fbeta)\n        losses.append(loss.detach().cpu().float())\n        accs.append(accuracy)\n    \n    del train_loader\n    del train_dataset\n    gc.collect()\n    \n    plt.plot(gaussian_filter1d(losses, sigma=10), label='loss')\n    plt.plot(gaussian_filter1d(accs, sigma=10), label='accs')\n    plt.plot(gaussian_filter1d(fbetas, sigma=10), label='fbetas')\n    plt.legend()\n\nfor fragment_number in TRAIN_ON_FRAGMENTS:\n    train(fragment_number)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:51:04.944749Z","iopub.execute_input":"2023-05-25T11:51:04.945108Z","iopub.status.idle":"2023-05-25T11:54:11.875004Z","shell.execute_reply.started":"2023-05-25T11:51:04.945074Z","shell.execute_reply":"2023-05-25T11:54:11.873965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validate the model","metadata":{}},{"cell_type":"code","source":"convnet.eval()\nval_dataset = SingleFragmentDataset(VAL_FRAGMENT)\nval_loader = thd.DataLoader(val_dataset, BATCH_SIZE, shuffle=True)\n\ndef evaluate(convnet, val_loader, threshold):\n    print(\"Evaluating for threshold %f\" % threshold)\n    losses = []\n    accs = []\n    fbetas = []\n    precisions = []\n    recalls = []\n\n    for i, (xs, ys) in enumerate(pbar := tqdm(val_loader)):\n        if i > MAX_VAL_STEPS:\n            break\n        outputs = convnet(xs.to(DEVICE))\n        loss = criterion(outputs, ys.to(DEVICE))\n        pred_ink = outputs.detach().gt(threshold).cpu().int()\n        accuracy = (pred_ink == ys).sum().float().div(ys.size(0))\n        fbeta = fbeta_score(ys.view(-1).numpy(), pred_ink.view(-1).numpy(), beta=0.5)\n        precision = precision_score(ys.view(-1).numpy(), pred_ink.view(-1).numpy())\n        recall = recall_score(ys.view(-1).numpy(), pred_ink.view(-1).numpy())\n        pbar.set_postfix({\"loss\": loss, \"acc\": accuracy, \"fbeta\": fbeta})\n\n        fbetas.append(fbeta)\n        losses.append(loss.detach().cpu().float())\n        accs.append(accuracy)\n        precisions.append(precision)\n        recalls.append(recall)\n    \n    return np.mean(losses), np.mean(accs), np.mean(fbetas), np.mean(precisions), np.mean(recalls)\n\n\ndef evaluate_for_thresholds():\n    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n    \n    best_fbeta = 0.\n    best_threshold = 0\n    \n    fbetas = []\n    precisions = []\n    recalls = []\n\n    for threshold in thresholds:\n        _, _, fbeta, precision, recall = evaluate(convnet, val_loader, threshold)\n        if fbeta > best_fbeta:\n            best_fbeta = fbeta\n            best_threshold = threshold\n        fbetas.append(fbeta)\n        precisions.append(precision)\n        recalls.append(recall)\n    \n    plt.plot(thresholds, fbetas, label=\"fbeta\")\n    plt.plot(thresholds, precisions, label=\"precision\")\n    plt.plot(thresholds, recalls, label=\"recall\")\n    plt.legend()\n    \n    return best_threshold\n\nbest_threshold = evaluate_for_thresholds()\nprint(\"Best threshold:\", best_threshold)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:55:18.128420Z","iopub.execute_input":"2023-05-25T11:55:18.129496Z","iopub.status.idle":"2023-05-25T11:56:25.046161Z","shell.execute_reply.started":"2023-05-25T11:55:18.129445Z","shell.execute_reply":"2023-05-25T11:56:25.045184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate test predictions","metadata":{}},{"cell_type":"code","source":"del val_loader\ndel val_dataset\ngc.collect()\n\nsubmission = defaultdict(list)\n\nfor fragment in ['a', 'b']:\n    pixels_with_ink = []\n    print(f\"Generating predictions for fragment {fragment}\")\n    test_dataset = SingleFragmentDataset(fragment, is_test=True)\n    test_loader = thd.DataLoader(test_dataset, BATCH_SIZE, shuffle=True)\n    for (xs, ys) in (pbar := tqdm(test_loader)):\n        outputs = convnet(xs.to(DEVICE))\n        pred_ink = outputs.detach().gt(best_threshold).flatten().cpu().int()\n        pred_ink = pred_ink[:len(ys)]\n        pixels_with_ink += ys[pred_ink == 1].int().tolist()\n    pixels_with_ink.sort()\n    \n    submission[\"Id\"].append(fragment)\n    submission[\"Predicted\"].append(' '.join(list(map(lambda p: \"%s 1\" % p, pixels_with_ink))))\n    \npd.DataFrame.from_dict(submission).to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:20:09.255630Z","iopub.status.idle":"2023-05-25T11:20:09.256358Z","shell.execute_reply.started":"2023-05-25T11:20:09.256089Z","shell.execute_reply":"2023-05-25T11:20:09.256114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(submission)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T11:20:09.257934Z","iopub.status.idle":"2023-05-25T11:20:09.258969Z","shell.execute_reply.started":"2023-05-25T11:20:09.258703Z","shell.execute_reply":"2023-05-25T11:20:09.258726Z"},"trusted":true},"execution_count":null,"outputs":[]}]}