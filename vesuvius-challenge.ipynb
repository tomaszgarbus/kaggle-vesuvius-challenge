{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Imports and constants","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport torch\nimport torch.utils.data as thd\nimport torch.nn as nn\n\nfrom sklearn.metrics import fbeta_score\n\nfrom scipy.ndimage.filters import gaussian_filter1d\n\nimport matplotlib.pyplot as plt\n\nfrom collections import defaultdict\nimport os\n\nBATCH_SIZE = 256\nBUFFER = 10  # Buffer size in both dimensions: x and y. Effective patch size is [BUFFER * 2 + 1, BUFFER * 2 + 1, Z_DIM].\nSLICES = 65\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nLEARNING_RATE = 0.003\nZ_START = 25\nZ_END = 40\nZ_DIM = Z_END - Z_START\n\nMAX_TRAIN_STEPS = 30000000\nMAX_VAL_STEPS = 1000\nPRINT_EVERY = 20000000","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-23T20:18:41.820855Z","iopub.execute_input":"2023-05-23T20:18:41.821569Z","iopub.status.idle":"2023-05-23T20:18:41.829047Z","shell.execute_reply.started":"2023-05-23T20:18:41.821535Z","shell.execute_reply":"2023-05-23T20:18:41.828142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, let's see if we can fit all one full fragment into memory at once.","metadata":{}},{"cell_type":"code","source":"def pad_array(array):\n    padding = (\n        (BUFFER, BUFFER),\n        (BUFFER, BUFFER),\n    )\n    return np.pad(array, padding)\n\ndef load_fragment_surface(fragment, split='train'):\n    print(\"Loading fragment %s surface\" % fragment)\n    surface_path = Path(\"/kaggle/input/vesuvius-challenge-ink-detection/%s/%s/surface_volume\" % (split, fragment))\n    return np.array([\n        pad_array(np.array(Image.open(f)))\n        for f in tqdm(sorted(surface_path.rglob(\"*.tif\"))[Z_START:Z_END])\n    ])\n\ndef load_mask(fragment, split='train'):\n    mask_path = Path(\"/kaggle/input/vesuvius-challenge-ink-detection/%s/%s/mask.png\" % (split, fragment))\n    return pad_array(np.array(Image.open(mask_path)))\n\ndef load_inklabels(fragment, split='train'):\n    inklabels_path = Path(\"/kaggle/input/vesuvius-challenge-ink-detection/%s/%s/inklabels.png\" % (split, fragment))\n    return pad_array(np.array(Image.open(inklabels_path)))","metadata":{"execution":{"iopub.status.busy":"2023-05-23T20:18:41.830753Z","iopub.execute_input":"2023-05-23T20:18:41.831016Z","iopub.status.idle":"2023-05-23T20:18:41.844071Z","shell.execute_reply.started":"2023-05-23T20:18:41.830994Z","shell.execute_reply":"2023-05-23T20:18:41.843311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SingleFragmentDataset(thd.Dataset):\n    def __init__(self, fragment, is_test=False):\n        self.is_test = is_test\n        split = 'test' if is_test else 'train'\n        self.surface = load_fragment_surface(fragment, split)\n        self.mask = load_mask(fragment, split)\n        self.inklabels = load_inklabels(fragment, split) if not is_test else None\n        self.pixels = np.stack(np.where(self.mask == 1), axis=1)\n    \n    def __len__(self):\n        return self.pixels.shape[0]\n    \n    def __getitem__(self, index):\n        x, y = self.pixels[index]\n        x_start = x - BUFFER\n        x_end = x + BUFFER + 1\n        y_start = y - BUFFER\n        y_end = y + BUFFER + 1\n        patch_surface = np.s_[:, x_start:x_end, y_start:y_end]\n        patch_labels = np.s_[x_start:x_end, y_start:y_end]\n#         return self.surface[patch_surface].astype(np.float32), self.inklabels[patch_labels].astype(np.float32)\n        surface = self.surface[patch_surface].astype(np.float32)\n        labels = self.inklabels[x, y].reshape((1, )).astype(np.float32) if not self.is_test else None\n        return (surface, labels) if not self.is_test else (surface, index)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T20:18:41.845527Z","iopub.execute_input":"2023-05-23T20:18:41.846299Z","iopub.status.idle":"2023-05-23T20:18:41.855143Z","shell.execute_reply.started":"2023-05-23T20:18:41.846264Z","shell.execute_reply":"2023-05-23T20:18:41.854433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_dataset = SingleFragmentDataset(1)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T20:18:41.856049Z","iopub.execute_input":"2023-05-23T20:18:41.856470Z","iopub.status.idle":"2023-05-23T20:18:47.195884Z","shell.execute_reply.started":"2023-05-23T20:18:41.856446Z","shell.execute_reply":"2023-05-23T20:18:47.194742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = thd.DataLoader(train_dataset, BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T20:18:47.198081Z","iopub.execute_input":"2023-05-23T20:18:47.198747Z","iopub.status.idle":"2023-05-23T20:18:47.207998Z","shell.execute_reply.started":"2023-05-23T20:18:47.198719Z","shell.execute_reply":"2023-05-23T20:18:47.207015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the model","metadata":{}},{"cell_type":"code","source":"convnet = nn.Sequential(\n    nn.Conv2d(Z_DIM, 32, kernel_size=3, stride=1, dilation=1, padding='same'),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Conv2d(32, 16, kernel_size=3, stride=1, dilation=1, padding='same'),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.BatchNorm2d(16),\n    nn.Conv2d(16, 8, kernel_size=3, stride=1, dilation=1, padding='same'),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.BatchNorm2d(8),\n    nn.Conv2d(8, 1, kernel_size=3, stride=1, dilation=1, padding='same'),\n    nn.ReLU(),\n    nn.Flatten(),\n    nn.Linear((2 * BUFFER + 1) ** 2, 128),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.Linear(128, 64),\n    nn.Dropout(p=0.2),\n    nn.ReLU(),\n    nn.Linear(64, 1),\n    nn.Sigmoid()\n).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T20:18:47.209189Z","iopub.execute_input":"2023-05-23T20:18:47.209997Z","iopub.status.idle":"2023-05-23T20:18:47.229778Z","shell.execute_reply.started":"2023-05-23T20:18:47.209971Z","shell.execute_reply":"2023-05-23T20:18:47.228986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train the model","metadata":{}},{"cell_type":"code","source":"%%time\nlosses = []\naccs = []\nfbetas = []\n\nconvnet.train()\ncriterion = nn.BCELoss()\noptimizer = torch.optim.SGD(convnet.parameters(), lr=LEARNING_RATE)\nfor i, (xs, ys) in enumerate(pbar := tqdm(train_loader)):\n    if i > MAX_TRAIN_STEPS:\n        break\n    optimizer.zero_grad()\n    outputs = convnet(xs.to(DEVICE))\n    if i % PRINT_EVERY == PRINT_EVERY - 1:\n        print(outputs)\n        plt.plot(gaussian_filter1d(losses, sigma=10), label='loss')\n        plt.plot(gaussian_filter1d(accs, sigma=10), label='accs')\n        plt.plot(gaussian_filter1d(fbetas, sigma=10), label='fbetas')\n        plt.legend()\n    loss = criterion(outputs, ys.to(DEVICE))\n    pred_ink = outputs.detach().gt(0.4).cpu().int()\n    accuracy = (pred_ink == ys).sum().float().div(ys.size(0))\n    fbeta = fbeta_score(ys.view(-1).numpy(), pred_ink.view(-1).numpy(), beta=0.5)\n    pbar.set_postfix({\"loss\": loss, \"acc\": accuracy, \"fbeta\": fbeta})\n    loss.backward()\n    optimizer.step()\n    \n    fbetas.append(fbeta)\n    losses.append(loss.detach().cpu().float())\n    accs.append(accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T20:18:47.230901Z","iopub.execute_input":"2023-05-23T20:18:47.231230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(gaussian_filter1d(losses, sigma=10), label='loss')\nplt.plot(gaussian_filter1d(accs, sigma=10), label='accs')\nplt.plot(gaussian_filter1d(fbetas, sigma=10), label='fbetas')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validate the model","metadata":{}},{"cell_type":"code","source":"del train_loader\ndel train_dataset\n\nconvnet.eval()\nval_dataset = SingleFragmentDataset(2)\nval_loader = thd.DataLoader(val_dataset, BATCH_SIZE, shuffle=True)\n\nlosses = []\naccs = []\nfbetas = []\n\nfor i, (xs, ys) in enumerate(pbar := tqdm(val_loader)):\n    if i > MAX_VAL_STEPS:\n        break\n    outputs = convnet(xs.to(DEVICE))\n    loss = criterion(outputs, ys.to(DEVICE))\n    pred_ink = outputs.detach().gt(0.4).cpu().int()\n    accuracy = (pred_ink == ys).sum().float().div(ys.size(0))\n    fbeta = fbeta_score(ys.view(-1).numpy(), pred_ink.view(-1).numpy(), beta=0.5)\n    pbar.set_postfix({\"loss\": loss, \"acc\": accuracy, \"fbeta\": fbeta})\n    \n    fbetas.append(fbeta)\n    losses.append(loss.detach().cpu().float())\n    accs.append(accuracy)\n\nprint(\"Mean loss: \", np.mean(losses))\nprint(\"Mean acc: \", np.mean(accs))\nprint(\"Mean fbetas: \", np.mean(fbetas))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate test predictions","metadata":{}},{"cell_type":"code","source":"del val_loader\ndel val_dataset\n\nsubmission = defaultdict(list)\n\nfor fragment in ['a', 'b']:\n    pixels_with_ink = []\n    print(f\"Generating predictions for fragment {fragment}\")\n    test_dataset = SingleFragmentDataset(fragment, is_test=True)\n    test_loader = thd.DataLoader(test_dataset, BATCH_SIZE, shuffle=True)\n    for (xs, ys) in (pbar := tqdm(test_loader)):\n        output = convnet(xs.to(DEVICE))\n        pred_ink = outputs.detach().gt(0.4).flatten().cpu().int()\n        pred_ink = pred_ink[:len(ys)]\n        pixels_with_ink += ys[pred_ink == 1].int().tolist()\n    pixels_with_ink.sort()\n    \n    submission[\"Id\"].append(fragment)\n    submission[\"Predicted\"].append(' '.join(list(map(lambda p: \"%s 1\" % p, pixels_with_ink))))\n    \npd.DataFrame.from_dict(submission).to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}